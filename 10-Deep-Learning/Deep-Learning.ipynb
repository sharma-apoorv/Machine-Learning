{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Lab 9: Multiclass Classification, Deep Learning, and Architecture Search</center>\n",
    "<center>DATA 558, Spring 2021</center>\n",
    "<center>Instructor: Zaid Harchaoui</center>\n",
    "<center>TAs: Alec Greaves-Tunnell and Ronak Mehta</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Overview\n",
    "\n",
    "In this lab, we will:\n",
    "- Implement three methods for extending classification to the multiclass setting.\n",
    "- Introduce Pytorch, a framework for differentiable machine learning.\n",
    "- Show how to implement simple neural network models in Pytorch.\n",
    "- Address the issue of scaling to large data with stochastic gradient descent (SGD).\n",
    "- Demonstrate a method for efficient and statistically principled comparison of many model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiclass Classification\n",
    "\n",
    "The broad theme of this lab is to introduce tools to handle \"scaling\" of a data science problem along one of several dimensions: the number of classes, the number of examples, or the number of models to consider. We begin with the first of these issues, generalizing binary classification to the multiclass case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data\n",
    "dat = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Hawks.csv')\n",
    "hawks = dat[['Tail','Wing','Species']].dropna()\n",
    "\n",
    "X = hawks[['Tail', 'Wing']]\n",
    "f, g = pd.factorize(hawks['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hawks['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 One-vs-rest\n",
    "\n",
    "Let the response $Y$ take values in $\\{1, 2, ..., C\\}$. In the one-vs-rest framework, we train $C$ binary classifiers, each of which attempts to distinguish a single class from all other classes. Formally, we define\n",
    "\n",
    "$$\n",
    "y_i^{(c)} = \\mathbb{1}\\{y_i = c\\}\n",
    "$$\n",
    "\n",
    "and we estimate\n",
    "\n",
    "$$\n",
    "\\beta^{(c)} = \\text{argmin}_{\\beta \\in \\mathbb{R}^d} \\frac{1}{n}\\sum_{i=1}^n \\ell(y_i^{(c)}, x_i; \\beta^{(c)}) + \\frac{1}{2}\\lambda ||\\beta^{(c)}||_2^2\n",
    "$$\n",
    "\n",
    "for every $c \\in C$. This involves solving $|C|$ optimization problems on a dataset with $n$ observations. Predictions are obtained by taking the class $c$ that maximizes the predicted probability of the class. In the case of logistic regression, this is equivalent to\n",
    "\n",
    "$$\n",
    "\\hat{f}(x) = \\text{argmax}_{c \\in \\{1, ..., C\\}} x^T\\beta^{(c)}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = {}\n",
    "for d in np.unique(f):\n",
    "    y_binary = np.where(f==d, 1, -1)\n",
    "    lr = LogisticRegression(C=1e-2, max_iter=350).fit(X, y_binary)\n",
    "    clfs[d] = {'model': lr,\n",
    "              'target': y_binary}\n",
    "    \n",
    "    preds = lr.predict(X)\n",
    "    print('Target = {}'.format(d))\n",
    "    print('Train acc = {:.3f}'.format(np.mean(preds==y_binary)))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `scikit-learn`, the one-vs-rest framework is implemented as a multiclass option for the `LogisticRegression` class. It is easy to check that the results are identical to training the collection of models defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1e-2,\n",
    "                         max_iter=350, \n",
    "                         multi_class='ovr').fit(X, f) # compare to sklearn\n",
    "\n",
    "clf.coef_ # (n_class x d) coefficient array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[clfs[d]['model'].coef_ for d in clfs.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1.1__: Implement one-vs-rest prediction on the data `X` using the models in `clfs`. Validate your prediction method by comparison to `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ovr_predict(clfs, X):\n",
    "    ## <YOUR CODE HERE>\n",
    "    scores = np.hstack([clfs[d]['model'].predict_proba(X)[:, 1][:, None] for d in clfs.keys()])\n",
    "    return np.argmax(scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ovr_preds = ovr_predict(clfs, X)\n",
    "np.mean(ovr_preds==clf.predict(X)) # compare predictions to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(ovr_preds==f) # compute accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll visualize the resulting multiclass classifier by plotting the _decision boundaries_ over a region containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot results over a grid\n",
    "def plot_multiclass_boundaries(X, f, grid_x, grid_y, grid_z,\n",
    "                              markers = ['x', 'o', 'v']):\n",
    "    plt.figure()\n",
    "    plt.contourf(grid_x, grid_y, grid_z, cmap=plt.cm.Set2)\n",
    "    for m, cls in enumerate(np.unique(f)):\n",
    "        ix = f==cls\n",
    "        plt.scatter(X.iloc[ix,0], X.iloc[ix,1], marker=markers[m], color=plt.cm.Set1(m))\n",
    "    plt.title(\"Multiclass decision surface\")\n",
    "    plt.xlabel(X.columns[0])\n",
    "    plt.ylabel(X.columns[1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# grid setup\n",
    "step = 1.0 \n",
    "x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n",
    "y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, step),\n",
    "                     np.arange(y_min, y_max, step))\n",
    "\n",
    "Z = ovr_predict(clfs, np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_multiclass_boundaries(X, f, xx, yy, Z.reshape(xx.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 One-vs-one\n",
    "\n",
    "Alternatively, we could train a collection of binary classifiers to distinguish between each _pair_ of classes, and then aggregate over the head-to-head prediction results to obtain a multiclass prediction. This approach is known as \"one-vs-one\", and it involves _reducing_ the data to every possible binary classification problem instead of _transforming_ it as in the one-vs-rest approach.\n",
    "\n",
    "For a training dataset in which $|C|$ classes are observed, there are \n",
    "\n",
    "$$\n",
    "{|C| \\choose 2} = \\frac{|C|(|C|-1)}{2} \\approx |C|^2\n",
    "$$\n",
    "\n",
    "unique pairs of classes - and thus models to train under the one-vs-one approach. The quadratic scaling in $C$ means that this approach can grow infeasible if the number of classes is large. On the other hand, the size of the data per classifier may be much smaller, which is useful for classifiers that scale unfavorably in $n$ (like kernel SVM).\n",
    "\n",
    "In the one-vs-one framework, predictions are obtained by taking the class that is predicted most frequently across all models in the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfs = {}\n",
    "for pair in itertools.combinations(np.unique(f), 2):\n",
    "    pair_ix = [x in pair for x in f]\n",
    "    X_pair = X.iloc[pair_ix, :]\n",
    "    y_pair = f[pair_ix]\n",
    "    y_pair_binary = np.where(y_pair==pair[1], 1, -1)\n",
    "    \n",
    "    lr = LogisticRegression(C=1e-2, \n",
    "                            max_iter=350).fit(X_pair, y_pair_binary)\n",
    "    clfs[pair] = {'model': lr,\n",
    "                  'pair': pair,\n",
    "              'target': y_pair_binary}\n",
    "    \n",
    "    preds = lr.predict(X_pair)\n",
    "    print('Pair = {}'.format(pair))\n",
    "    print('Train acc = {:.3f}'.format(np.mean(preds==y_pair_binary)))\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `scikit-learn`, the `OneVsOneClassifier` class takes any estimator object with `fit()` and `predict_proba()` methods. We can again compare the results to our manual implementation above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "ovo_lr = OneVsOneClassifier(LogisticRegression(C=1e-2, max_iter=350)).fit(X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[x.coef_ for x in ovo_lr.estimators_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[x['model'].coef_ for x in clfs.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1.2__: Implement one-vs-one prediction on the data `X` using the models in `clfs`. Validate your prediction method by comparison to `sklearn`. You may wish to use the `scipy.stats` function `mode` (imported below) to compute the most frequent value along some axis of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "\n",
    "def ovo_predict(clfs, X):\n",
    "    ## <YOUR CODE HERE>\n",
    "    votes = np.hstack([np.array([clfs[pair]['pair'][x] \n",
    "                                 for x in clfs[pair]['model'].predict(X)])[:, None] \n",
    "                       for pair in pairs])\n",
    "    return mode(votes, axis=1)[0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ovo_preds = ovo_predict(clfs, X)\n",
    "np.mean(ovo_preds==ovo_lr.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(ovo_preds==f) # compute accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plots\n",
    "Z = ovo_predict(clfs, np.c_[xx.ravel(), yy.ravel()])\n",
    "plot_multiclass_boundaries(X, f, xx, yy, Z.reshape(xx.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Multinomial loss\n",
    "\n",
    "Finally, as an alternative to generating a multiclass prediction from an ensemble of binary classifiers, we can consider directly estimating a statistical model for a categorical outcome $Y$ that takes more than two values. The random variable $Y$ has a categorical distribution if it satisfies\n",
    "\n",
    "$$\n",
    "p(Y = c) = p_c\n",
    "$$\n",
    "\n",
    "with $0 \\leq p_c \\leq 1$ for $c=1,...,C$ and $\\sum_{c=1}^C p_c = 1$. In multinomial logistic regression, we model the conditional distribution $p(Y | X=x)$ as categorical with probabilities\n",
    "\n",
    "\\begin{align}\n",
    "p(Y = 1 | X=x) &= \\frac{\\exp(x^T\\beta^{(1)})}{1+\\sum_{c=1}^{C-1} x^T\\beta^{(c)}}, \\\\\n",
    "p(Y = 2 | X=x) &= \\frac{\\exp(x^T\\beta^{(2)})}{1+\\sum_{c=1}^{C-1} x^T\\beta^{(c)}}, \\\\\n",
    "&\\vdots \\\\\n",
    "p(Y=C | X=x) &= \\frac{1}{1+\\sum_{c=1}^{C-1} x^T\\beta^{(c)}},\n",
    "\\end{align}\n",
    "\n",
    "where the form of the final probability $p_C$ is chosen to ensure that $\\sum_{c=1}^C p_c = 1$.\n",
    "\n",
    "\n",
    "The multinomial logistic regression optimization problem is then given by\n",
    "\n",
    "$$\n",
    "\\text{min}_{\\beta_1, ..., \\beta_C \\in \\mathbb{R}^d} \\frac{1}{n} \\sum_{i=1}^n \\ell(y_i, x_i; \\beta) + \\sum_{c=1}^C ||\\beta_c||_2^2,\n",
    "$$\n",
    "where the _multinomial loss_ writes as\n",
    "$$\n",
    "\\ell(y_i, x_i; \\beta) = \\sum_{c=1}^C \\mathbb{1}\\{y_i = c\\} p(Y = c | X=x_i).\n",
    "$$\n",
    "\n",
    "Given a new observation $x^*$, the probability $p(Y = c | X=x^*)$ is computed via the expressions above, and we predict\n",
    "\n",
    "$$\n",
    "\\hat{f}(x^*) = \\text{argmax}_{c \\in \\{1, ..., C\\}} \\ \\ p(Y = c | X=x^*).\n",
    "$$\n",
    "\n",
    "Multinomial logistic regression is implemented as an multiclass option for the `LogisticRegression` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=1e-2, \n",
    "                         max_iter=350, \n",
    "                         multi_class='multinomial').fit(X, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multi_preds = clf.predict(X)\n",
    "np.mean(multi_preds==f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "plot_multiclass_boundaries(X, f, xx, yy, Z.reshape(xx.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Exercise 1.3__: What are the relative advantages and disadvantages of the three approaches to multiclass classficiation described above? What is the practical difference in terms of prediction accuracy on the given data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch Basics\n",
    "\n",
    "In this section, we introduce the syntax of the [PyTorch](https://pytorch.org/) library for deep learning and optimization. Libraries such as PyTorch enable us to run massive computations on the GPU, which is essential for building large-scale neural models. A PyTorch project usually consists of the following components. While these are not very different from the typical components of a machine learning pipeline, they must be implemented in a specific way. \n",
    "\n",
    "- **Tensors**: The PyTorch `Tensor` can be thought of as analogous to the `numpy.ndarray`. We often will have tensors that are higher than 2D.\n",
    "- **Device**: The *device* refers to either CPU or GPU, depending on where models/tensors are stored, and computation happens.\n",
    "- **Dataset / Dataloader**: We instantiate (and sometimes implement) a `Dataset` class which specifies how to index the training, validation, and test data. This is then used to create a `DataLoader` class which specifies a scheme for loading batches of data, used both in training (e.g. stochastic gradient descent) and validation (e.g. batch-level accuracy). \n",
    "- **Architecture / Forward Pass**: We use a `Module` class to specify an *architecture* for our neural network ( layers, activations, etc.). The term *forward pass* refers to the sequence of computations that the network runs on an input given its parameters. Crucially, you implement the forward pass in the `forward` method, and the software uses automatic differentiation algorithms to compute the gradient without hand-coding it.\n",
    "- **Loss**: This is the final tensor which results from pushing the output of the network and the true labels through a function, usually called `criterion`. After this step, we call `backward` on the loss tensor in order to compute the gradient via the backpropagation algorithm (this is called the *backward pass*).\n",
    "- **Optimizer**: The `Optimizer` abstraction allows one to compute steps of iterative algorithms such as stochastic gradient descent. We call `step` on this object after the backward pass, which automatically runs the update step.\n",
    "\n",
    "We put all of these operations together in the *training loop* and *evaluation loop* seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Datasets and Dataloaders\n",
    "\n",
    "We will use two running examples. A simple simulated dataset $(x_1, y_1), ..., (x_n, y_n)$ with each $y_i \\sim \\text{Bernoulli}\\left(\\frac{1}{2}\\right)$, and given $y$,\n",
    "$$\n",
    "x \\sim \\begin{cases}\n",
    "\\mathcal{N}(\\mu 1_d, \\sigma_1 I_d) &\\text{ if } y = 1\\\\\n",
    "\\mathcal{N}(-\\mu 1_d, \\sigma_0 I_d) &\\text{ if } y = 0\n",
    "\\end{cases},\n",
    "$$\n",
    "as well as the Fashion MNIST dataset. To implement a `Dataset`,  you must implement a `__len__` method (which returns the number of examples) and a `__getitem__` method, which returns the example at a particular index. Functions such as `TensorDataset` can make it so that you do not have to implement the class yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SimulatedDataset(Dataset):\n",
    "    def __init__(self, n, d, mean_scale=0.62, cov_scales=[1.0, 0.5]):\n",
    "        self.n = n\n",
    "        self.labels = torch.bernoulli(0.5 * torch.ones(n)).long()\n",
    "        distributions = [\n",
    "            torch.distributions.MultivariateNormal(\n",
    "                -mean_scale * torch.ones(d),\n",
    "                covariance_matrix=cov_scales[0] * torch.eye(d),\n",
    "            ),\n",
    "            torch.distributions.MultivariateNormal(\n",
    "                mean_scale * torch.ones(d),\n",
    "                covariance_matrix=cov_scales[1] * torch.eye(d),\n",
    "            ),\n",
    "        ]\n",
    "        self.examples = []\n",
    "        for i in range(n):\n",
    "            self.examples.append(distributions[int(self.labels[i])].sample())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.examples[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have a `Dataset`, we can create a `DataLoader`, which is an iterable that cycles through batches of data. Some common schemes for sampling batches are the `RandomSampler` and `SequentialSampler`. Each batch will return a tuple based on the implementation of `__gititem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "\t X shape: torch.Size([32, 10])\n",
      "\t y shape: torch.Size([32])\n",
      "Batch 1:\n",
      "\t X shape: torch.Size([32, 10])\n",
      "\t y shape: torch.Size([32])\n",
      "Batch 2:\n",
      "\t X shape: torch.Size([16, 10])\n",
      "\t y shape: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, random_split\n",
    "\n",
    "n = 100\n",
    "d = 10\n",
    "batch_size = 32\n",
    "val_size = 0.2\n",
    "\n",
    "dataset = SimulatedDataset(n, d)\n",
    "\n",
    "val_len = int(len(dataset) * val_size)\n",
    "train_len = len(dataset) - val_len\n",
    "\n",
    "training_data, val_data = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "train_dataloader = DataLoader(training_data, sampler=RandomSampler(training_data), batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_data, sampler=RandomSampler(val_data), batch_size=batch_size)\n",
    "\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    X_batch, y_batch = batch\n",
    "    \n",
    "    print(\"Batch %d:\" % i)\n",
    "    print(\"\\t X shape:\", X_batch.shape)\n",
    "    print(\"\\t y shape:\", y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Architecture\n",
    "\n",
    "Next, we implement a neural network architecture. This usually amounts to defining *layers*, which are objects that can be called on inputs, in the `__init__` function, and implementing the forward pass in the `forward` function. Below, we implement the simple network below. Let $x \\in \\mathbb{R}^d$, and consider\n",
    "\n",
    "$$\n",
    "p_\\theta(y\\mid x) = \\text{Softmax}(W_2\\text{ReLU}(W_1 x + b_1) + b_2),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(z) = \\max\\{0, z\\}\n",
    "$$\n",
    "\n",
    "is applied element-wise, and\n",
    "\n",
    "$$\n",
    "\\left(\\text{Softmax}(z)\\right)_i = \\frac{e^{z_i}}{\\sum_{j=1}^k e^{z_j}}\n",
    "$$\n",
    "\n",
    "for $z \\in \\mathbb{R}^k$. The parameter $\\theta = (W_1, b_1, W_2, b_2)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.1**: If the hidden layer (the vector that results from the ReLU) has dimension $h$, and the Softmaz outputs 2 units, what are the dimensions of $W_1$, $b_1$, $W_2$, $b_2$?\n",
    "\n",
    "**Solution**:\n",
    "$$\n",
    "\\begin{align*}\n",
    "W_1 &\\in \\mathbb{R}^{h \\times d}\\\\\n",
    "b_1 &\\in \\mathbb{R}^h\\\\\n",
    "W_2 &\\in \\mathbb{R}^{2 \\times h}\\\\\n",
    "b_2 &\\in \\mathbb{R}^2\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement this network below. Notice some of the style choices (the line by line implementation in `forward`), and how the layers are callable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        out = self.softmax(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SimpleNet(d, d, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Loss and Optimizer\n",
    "\n",
    "The final elements to specify before we start training are the *loss* and the *optimizer*. PyTorch comes with many built in versions of both of these, so we really just have to specify them by name. You can of course implement your own custom versions as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # log-loss\n",
    "optimizer = SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Training and Evaluation\n",
    "\n",
    "We can now put it all together! To train, we run the following loop. We usually measure iterations in *epochs*, or number of passes through the training set. The number of iterations within one batch is the sample size divided by the batch size. We record performance on a validation set after each epoch. We also save a checkpoint of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def seed_everything(seed_val=42):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 validation accuracy: 0.65\n",
      "Epoch 1 validation accuracy: 0.75\n",
      "Epoch 2 validation accuracy: 0.80\n",
      "Epoch 3 validation accuracy: 0.85\n",
      "Epoch 4 validation accuracy: 0.90\n",
      "Epoch 5 validation accuracy: 0.95\n",
      "Epoch 6 validation accuracy: 0.95\n",
      "Epoch 7 validation accuracy: 0.95\n",
      "Epoch 8 validation accuracy: 0.95\n",
      "Epoch 9 validation accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "seed_everything(seed_val=42)                                          # 0. Seed everything.\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\" # 1. Set device.\n",
    "model.to(device)                                                      # 2. Send model to device.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    model.train()                                                     # 3. Set model to training mode.\n",
    "    \n",
    "    for (x_batch, y_batch) in train_dataloader:\n",
    "        \n",
    "        model.zero_grad()                                             # 4. Prevents gradients from accumulating.\n",
    "        \n",
    "        x_batch.to(device)                                            # 5. Send data to device.\n",
    "        y_batch.to(device)\n",
    "        outputs = model(x_batch)                                      # 6. Forward pass (compute outputs).\n",
    "        \n",
    "        loss = criterion(outputs, y_batch)                            # 7. Compute loss.\n",
    "        \n",
    "        loss.backward()                                               # 8. Backward pass (compute gradient).\n",
    "        \n",
    "        optimizer.step()                                              # 9. Update parameters.\n",
    "        \n",
    "    model.eval()                                                      # 10. Set model to evaluation mode.\n",
    "    \n",
    "    val_accuracy = []\n",
    "    for (x_batch, y_batch) in val_dataloader:\n",
    "        \n",
    "        with torch.no_grad():                                         # 11. Do not keep track of operations.\n",
    "            \n",
    "            x_batch.to(device)                                        # 12. Send data to device.\n",
    "            y_batch.to(device)\n",
    "            outputs = model(x_batch)                                  # 13. Forward pass (compute outputs).\n",
    "            \n",
    "            y_pred = torch.argmax(outputs, axis=1)                    # 14. Compute validation performance.\n",
    "            val_accuracy.append(torch.mean((y_pred == y_batch).float()).item())\n",
    "    print(\"Epoch %d validation accuracy: %0.2f\" % (epoch, np.array(val_accuracy).mean()))\n",
    "            \n",
    "    torch.save(model.state_dict(), \"simple_net.pt\")                   # 15. Save checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a lot of these steps might seem overkill for a simple example, we will run through the whole process once again with the Fashion MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Example: Fashion MNIST\n",
    "\n",
    "Fashion-MNIST is a dataset of [Zalando](https://jobs.zalando.com/en/tech/?gh_src=nevh2y1)'s article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = FashionMNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_data = FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_val_dataloaders(dataset, val_size, batch_size):\n",
    "\n",
    "    if val_size > 0 and val_size < 1:\n",
    "        val_size = int(val_size * len(dataset))\n",
    "    train_size = len(dataset) - val_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    print(\"{:>5,} training samples\".format(train_size))\n",
    "    print(\"{:>5,} validation samples\".format(val_size))\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=RandomSampler(train_dataset), \n",
    "        batch_size=batch_size, \n",
    "    )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        sampler=RandomSampler(val_dataset),  \n",
    "        batch_size=batch_size,  \n",
    "    )\n",
    "\n",
    "    return train_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48,000 training samples\n",
      "12,000 validation samples\n",
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "val_size = 0.2\n",
    "\n",
    "train_dataloader, val_dataloader = get_train_val_dataloaders(training_data, val_size, batch_size)\n",
    "\n",
    "for x_batch, y_batch in train_dataloader:\n",
    "    print(x_batch.shape)\n",
    "    print(y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.2**: Implement `LessSimpleNet`, which should take an image of size `input_dim`-by-`input_dim`, feed it through `num_layers` fully-connected layers with ReLU activations of size `hidden_dim`, and finally produce a Softmax output layer of size `ouput_dim`. (*Hint:* if you would like to store your layers in a list, use an instance of `nn.ModuleList`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LessSimpleNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LessSimpleNet, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        if num_layers > 0:\n",
    "            self.layers.append(nn.Linear(input_dim * input_dim, hidden_dim))\n",
    "            if num_layers > 1:\n",
    "                for l in range(num_layers - 1):\n",
    "                    self.layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            self.layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        else:\n",
    "            # Logistic regression.\n",
    "            self.layers.append(nn.Linear(input_dim * input_dim, output_dim))\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten.\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape(batch_size, -1)\n",
    "        \n",
    "        # Apply fully connected layers.\n",
    "        x = self.layers[0](x)\n",
    "        for layer in self.layers[1:]:\n",
    "            x = F.relu(x)\n",
    "            x = layer(x)\n",
    "        out = self.softmax(x)\n",
    "        return out\n",
    "    \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv = nn.Conv2d(1, 4, 5)\n",
    "        self.bn = nn.BatchNorm2d(4)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear((input_dim - 4) ** 2 * 4, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        out = self.softmax(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 28   # Size of image.\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "output_dim = 10  # Number of classes.\n",
    "lr = 0.01        # Notice the smaller learning rate.\n",
    "epochs = 10\n",
    "\n",
    "model = LessSimpleNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "# model = ConvNet(input_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat the same training loop as last time. Because this is a larger scale problem, it can be nice to catch `KeyboardInterrupt` exceptions in case we have to restart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 validation accuracy: 0.78\n",
      "Epoch 1 validation accuracy: 0.80\n",
      "Epoch 2 validation accuracy: 0.81\n",
      "Epoch 3 validation accuracy: 0.83\n",
      "Epoch 4 validation accuracy: 0.84\n",
      "Epoch 5 validation accuracy: 0.85\n",
      "Epoch 6 validation accuracy: 0.85\n",
      "Epoch 7 validation accuracy: 0.85\n",
      "Epoch 8 validation accuracy: 0.85\n",
      "Epoch 9 validation accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed_val=42)                                          \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\" \n",
    "model.to(device)                                                    \n",
    "\n",
    "try:\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        model.train()                                                   \n",
    "\n",
    "        for (x_batch, y_batch) in train_dataloader:\n",
    "\n",
    "            model.zero_grad()                                           \n",
    "\n",
    "            x_batch.to(device)                                           \n",
    "            y_batch.to(device)\n",
    "            outputs = model(x_batch)                                   \n",
    "\n",
    "            loss = criterion(outputs, y_batch)                       \n",
    "\n",
    "            loss.backward()                                           \n",
    "\n",
    "            optimizer.step()                                             \n",
    "\n",
    "        model.eval()                                                    \n",
    "\n",
    "        val_accuracy = []\n",
    "        for (x_batch, y_batch) in val_dataloader:\n",
    "\n",
    "            with torch.no_grad():                                        \n",
    "\n",
    "                x_batch.to(device)                                       \n",
    "                y_batch.to(device)\n",
    "                outputs = model(x_batch)                                 \n",
    "\n",
    "                y_pred = torch.argmax(outputs, axis=1)                    \n",
    "                val_accuracy.append(torch.mean((y_pred == y_batch).float()).item())\n",
    "\n",
    "        print(\"Epoch %d validation accuracy: %0.2f\" % (epoch, np.array(val_accuracy).mean()))\n",
    "\n",
    "        torch.save(model.state_dict(), \"less_simple_net.pt\")\n",
    "        # torch.save(model.state_dict(), \"conv_net.pt\")\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Graceful Exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(test_data, sampler=RandomSampler(test_data), batch_size=1024)\n",
    "\n",
    "model = LessSimpleNet(input_dim, hidden_dim, output_dim, num_layers)\n",
    "model.load_state_dict(torch.load(\"less_simple_net.pt\"))\n",
    "# model = ConvNet(input_dim, output_dim)\n",
    "# model.load_state_dict(torch.load(\"conv_net.pt\"))\n",
    "model.eval()\n",
    "\n",
    "test_accuracy = []\n",
    "for (x_batch, y_batch) in test_dataloader:\n",
    "    with torch.no_grad():                                        \n",
    "\n",
    "        x_batch.to(device)                                       \n",
    "        y_batch.to(device)\n",
    "        outputs = model(x_batch)                                 \n",
    "\n",
    "        y_pred = torch.argmax(outputs, axis=1)                    \n",
    "        test_accuracy.append(torch.mean((y_pred == y_batch).float()).item())\n",
    "\n",
    "print(\"Test accuracy: %0.2f\" % np.array(test_accuracy).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Architecture Search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The networks introduced in the previous section have a number of hyperparameters - namely, `num_layers` and `hidden_dim`. Additionally, our choice of learning rate `lr` will depend on the chosen architecture (for neural networks, the learning rate choice is usually more critical than in convex problems).\n",
    "\n",
    "One option is grid search. However, given that training each model can take a very long time, especially in larger-scale probelms, intelligent ways of performing hyperparameter and architecture search are increasingly important. We present on such way: **model-racing**. The idea is to start training many models via SGD, but at each step of the way, \"knock out\" models that are statistically significantly worse than the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisely, let $N$ be the number of batches seen thus far, and consider $M$ models $h^{(N)}_1, ..., h^{(N)}_M$, where $h^{(N)}_m$ is the $m$-th model trained with $N$ iterates of (minibatch) stochastic gradient descent. Before training on the $(N+1)$-th batch $B^{(N+1)}$, we compute a running average accuracy $A^{(N+1)}_m$ for each model, given by\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    A^{(N+1)}_m &= \\frac{1}{N+1} \\cdot  (\\text{accuracy of $h^{(N)}_m$ on $B^{(N+1)}$}) + \\frac{N}{N+1} \\cdot A^{(N)}_m\\\\\n",
    "    A^{(N+1)}_m &= \\frac{1}{N+1} \\cdot \\frac{1}{|B^{(N+1)}|}\\sum_{(x, y) \\in B^{(N+1)}} \\mathbb{I}(y = h^{(N)}_m(x)) + \\frac{N}{N+1} \\cdot A^{(N)}_m\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "While this looks a little hairy, it is just the average of all of the accuracies of the model on all batches before training on them.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "A^{(N)}_m &= \\frac{1}{N}\\sum_{n=1}^{N} (\\text{accuracy of $h^{(n)}_m$ on $B^{(n)}$})\\\\\n",
    "A^{(N)}_m &= \\frac{1}{N}\\sum_{n=1}^{N} \\frac{1}{|B^{(n)}|}\\sum_{(x, y) \\in B^{(n)}} \\mathbb{I}(y = h^{(n)}_m(x))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then, let $\\delta$ be the chance that we miss the best model (this is specified by us, exactly analogous to $\\alpha$ in hypothesis testing). We define bounds around each accuracy to form confidence intervals. That is, given width $w^{(N)}_{m}$, we generate\n",
    "\n",
    "$$\n",
    "\\text{CI}^{(N)}_{m} = [A^{(N)}_m - w^{(N)}_{m}, A^{(N)}_m + w^{(N)}_{m}]\n",
    "$$\n",
    "\n",
    "There are multiple choices of $w^{(N)}_{m}$ that make these valid confidence intervals, derived from theoretical probability bounds. We will not focus on the particular width chosen, but the overall procedure. Finally, we find the highest upper bound, that is\n",
    "\n",
    "$$\n",
    "    L^{(N)} = \\max_{m=1, ..., M} A^{(N)}_m - w^{(N)}_{m}\n",
    "$$\n",
    "\n",
    "This represents the \"best\" lower limit among the models. We then eliminate the models whose upper limit is lower than this, i.e. any model $m$ that satisfies\n",
    "$$\n",
    "    A^{(N)}_m + w^{(N)}_{m} < L^{(N)}\n",
    "$$\n",
    "\n",
    "In summary, we create measures of performance for all models while training them, and eliminate a model when its entire confidence interval is lower than that of another model. Crucially, the training step can always be done in parallel. This will be come significantly clearer with a visual, and then pseuodocode.\n",
    "\n",
    "**Note**: The original model racing algorithm would train leave-one-out models on all batches for each $N$. We use an inexpensive approximation here, by just averaging the accuracies of the previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate models by randomly sampling hyperparameters from a specified range. We do this `num_models` times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def get_model_list(num_models, num_layers_range, hidden_dim_range, lr_range, input_dim, output_dim, device):\n",
    "    \n",
    "    num_layers = np.random.choice(num_layers_range, num_models)\n",
    "    hidden_dim = np.random.choice(hidden_dim_range, num_models)\n",
    "    lr = np.random.choice(lr_range, num_models)\n",
    "    \n",
    "    models = []\n",
    "    colors = list(mcolors.CSS4_COLORS.keys())\n",
    "    for i in range(num_models): \n",
    "        model = LessSimpleNet(input_dim, hidden_dim[i], output_dim, num_layers[i])\n",
    "        model.to(device)\n",
    "        models.append({\n",
    "            \"model\" : model,\n",
    "            \"optimizer\" : SGD(model.parameters(), lr=lr[i]),\n",
    "            \"id\" : i,\n",
    "            \"params\" : {\"num_layers\": num_layers[i], \"hidden_dim\": hidden_dim[i], \"lr\": lr[i]},\n",
    "            \"train_accs\" : [],\n",
    "            \"intervals\" : [],\n",
    "            \"color\" : colors[i % 148],\n",
    "            \"eliminated\" : False\n",
    "        })\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step(x_batch, y_batch, model_dict, criterion):\n",
    "    model = model_dict[\"model\"]\n",
    "    optimizer = model_dict[\"optimizer\"]\n",
    "    \n",
    "    model.train()\n",
    "    model.zero_grad()                                           \n",
    "    outputs = model(x_batch)                                   \n",
    "    loss = criterion(outputs, y_batch)                       \n",
    "    loss.backward()                                           \n",
    "    optimizer.step()\n",
    "    \n",
    "def eval_step(x_batch, y_batch, model_dict):\n",
    "    model = model_dict[\"model\"]\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():                                        \n",
    "\n",
    "        outputs = model(x_batch)                                 \n",
    "        y_pred = torch.argmax(outputs, axis=1)           \n",
    "        return torch.mean((y_pred == y_batch).float()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bernstein_bound(delta, num_batches, num_models):\n",
    "    return np.sqrt(2 / (4 * num_batches) * np.log(2 * num_batches * num_models / delta)) + 4 / (3 * num_batches) * np.log(2 * num_batches * num_models / delta)\n",
    "\n",
    "def update_intervals(batch_accuracy, model_dict, delta, num_batches, num_models):\n",
    "    \n",
    "    if num_batches > 1:\n",
    "        mean = ((num_batches - 1) * model_dict[\"train_accs\"][-1] + batch_accuracy) / num_batches\n",
    "    else:\n",
    "        mean = batch_accuracy\n",
    "    bound = bernstein_bound(delta, num_batches, num_models)\n",
    "    # bound = hoeffding_bound(delta, num_batches)\n",
    "    \n",
    "    return mean, mean - bound, mean + bound\n",
    "\n",
    "def eliminate(model_list, num_batches):\n",
    "    \n",
    "    lower_bounds = []\n",
    "    for model_dict in model_list:\n",
    "        if not model_dict[\"eliminated\"]:\n",
    "            lower_bounds.append(model_dict[\"intervals\"][num_batches - 1][1])\n",
    "    max_lower_bound = np.max(lower_bounds)\n",
    "    \n",
    "    for model_dict in model_list:\n",
    "        if not model_dict[\"eliminated\"]:\n",
    "            # Upper bound exceeds maximum of the lower bounds.\n",
    "            if model_dict[\"intervals\"][num_batches - 1][2] <= max_lower_bound:\n",
    "                model_dict[\"eliminated\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following hyperparameters determine these ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 28   \n",
    "hidden_dim = 128\n",
    "num_layers = 1\n",
    "output_dim = 10 \n",
    "\n",
    "num_models = 100\n",
    "num_layers_range = [0, 1, 2]\n",
    "hidden_dim_range = [64, 128, 256]\n",
    "lr_range = [1e-3, 1e-2, 1e-1]\n",
    "\n",
    "parallel = False\n",
    "\n",
    "epochs = 2\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "delta = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this training loop is slightly different than what we have seen before, the structure is largely the same. We have just wrapped up previous boilerplate code into `train_step` and `eval_step`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "seed_everything(seed_val=42)\n",
    "step = 5\n",
    "\n",
    "model_list = get_model_list(num_models, num_layers_range, hidden_dim_range, lr_range, input_dim, output_dim, device)\n",
    "\n",
    "num_batches = 0\n",
    "try:\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for (x_batch, y_batch) in train_dataloader:\n",
    "\n",
    "            num_batches += 1\n",
    "\n",
    "            # Send data to device.\n",
    "            x_batch.to(device)                                       \n",
    "            y_batch.to(device)\n",
    "\n",
    "            def worker(model_dict):\n",
    "                # If this model has not already been knocked out of the race.\n",
    "                if not model_dict[\"eliminated\"]:\n",
    "                    # Before training, evaluate accuracy on this batch and update confidence intervals.\n",
    "                    batch_accuracy = eval_step(x_batch, y_batch, model_dict)\n",
    "                    mean, lower, upper = update_intervals(batch_accuracy, model_dict, delta, num_batches, num_models)\n",
    "\n",
    "                    # Now, train on the batch.\n",
    "                    train_step(x_batch, y_batch, model_dict, criterion)\n",
    "                    \n",
    "                    return mean, lower, upper\n",
    "                else:\n",
    "                    return (0, 0, 0) # Placeholder for eliminated models.\n",
    "                \n",
    "            if parallel:\n",
    "                intervals = np.array(Parallel(n_jobs=-2)(delayed(worker)(model_dict) for model_dict in model_list))\n",
    "            else:\n",
    "                intervals = np.array([worker(model_dict) for model_dict in model_list])\n",
    "            \n",
    "            for i, model_dict in enumerate(model_list):\n",
    "                if not model_dict[\"eliminated\"]:\n",
    "                    model_dict[\"train_accs\"].append(intervals[i, 0])\n",
    "                    model_dict[\"intervals\"].append(intervals[i])\n",
    "\n",
    "            # Eliminate worst performing models.\n",
    "            if num_batches % step == 0:\n",
    "                eliminate(model_list, num_batches)\n",
    "\n",
    "    pickle.dump(model_list, open(\"model_list.p\", \"wb\"))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Graceful Exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "model_list = pickle.load(open(\"model_list.p\", \"rb\"))\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "displayed_batches = num_batches\n",
    "# displayed_batches = 1000\n",
    "\n",
    "try:\n",
    "    for frame, nb in enumerate(np.arange(displayed_batches)+1):    \n",
    "        ax.clear()\n",
    "\n",
    "        y = []\n",
    "        colors = []\n",
    "        remaining_models = 0\n",
    "        for model_dict in model_list:\n",
    "            if len(model_dict[\"train_accs\"]) >= nb:\n",
    "                y.append(model_dict[\"train_accs\"][nb - 1])\n",
    "                colors.append(model_dict[\"color\"])\n",
    "                remaining_models += 1\n",
    "        x = np.arange(remaining_models)\n",
    "        yerr = bernstein_bound(delta, nb, num_models)\n",
    "\n",
    "        ax.set_ylim(-0.05, 1.05)\n",
    "        ax.errorbar(x, y, yerr=yerr, linestyle=' ', ecolor=colors, elinewidth=4)\n",
    "        ax.set_title(\"Race at %d batches\" % nb)\n",
    "        ax.set_xticklabels([])\n",
    "        ax.legend(['Models left: {}'.format(remaining_models)])\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "        time.sleep(.01)\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Graceful Exit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_layers': 0, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 0, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 0, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 128, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 0, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 128, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 0, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 128, 'lr': 0.1}\n",
      "{'num_layers': 0, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 128, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 128, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 128, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 128, 'lr': 0.1}\n",
      "{'num_layers': 2, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 0, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 128, 'lr': 0.1}\n",
      "{'num_layers': 1, 'hidden_dim': 64, 'lr': 0.1}\n",
      "{'num_layers': 0, 'hidden_dim': 256, 'lr': 0.1}\n",
      "{'num_layers': 0, 'hidden_dim': 64, 'lr': 0.1}\n"
     ]
    }
   ],
   "source": [
    "for model_dict in model_list:\n",
    "    if not model_dict[\"eliminated\"]:\n",
    "        print(model_dict[\"params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
