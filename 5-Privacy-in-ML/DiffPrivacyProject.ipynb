{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7e2ac0",
   "metadata": {},
   "source": [
    "# <center>Data Science Project Part 1:  Differential Privacy</center>\n",
    "<center>DATA 558, Spring 2021</center>\n",
    "<center>TAs: Alec Greaves-Tunnell and Ronak Mehta</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ba9c48",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8a2900",
   "metadata": {},
   "source": [
    "#### Name: Apoorv Sharma\n",
    "#### Partner:  Hasnah Said\n",
    "#### Summary of findings:\n",
    "\n",
    "    A: M1 is not differentially private. There is no randomness involved when returning the results.\n",
    "\n",
    "    B: 'scale' parm is not used for M3. Moreover, this method is also not differentially private.\n",
    "    \n",
    "    C: Implement Laplace Mechanism\n",
    "    \n",
    "    D: Check for differentialy privacy\n",
    "    \n",
    "    E: The data scaled on all of X, rather than just X_train\n",
    "    \n",
    "    F: The mechanism should only be trained using the train datasets, not the whole datatset. As a result, we also need to implement a custom `train_test_split` function so that we can also split the attributes in the correct manner. \n",
    "    \n",
    "    G: Incorrect implementation of Bayes rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d435e",
   "metadata": {},
   "source": [
    "## Dataset: Animals with Attributes v2\n",
    "\n",
    "The data comes from Animals with Attributes v2 dataset, which contains images of 50 different types of animals, with each animal labeled with various attributes (whether it flies, whether it has a tail, etc.). In this example, we will not use the images, and treat the classes themselves as datapoints. That is, we will have $n = 50$ data points $(x_1, y_1), ..., (x_n, y_n)$, where $x_i \\in \\{0, 1\\}^d$ is a binary vector of attributes, and $y_i \\in \\{0, 1\\}$ is a binary label indicating whether the animal is an `ocean` animal or not. There were originally 85 attributes, but we have subsetted them to $d = 5$ features, namely:\n",
    "\n",
    "- `horns` - whether the animal has horns.\n",
    "- `tree` - whether the animal lives in a tree.\n",
    "- `bulbous` - whether the animal is stocky.\n",
    "- `fierce` - whether the animal is fierce.\n",
    "- `arctic` - whether the animal lives in the arctic.\n",
    "\n",
    "Additionally, we have one protected attribute, `flippers`, indicating whether the animal has flippers. This attribute is known for 49 of the animals, but is unknown for a held out animal, the `buffalo`. We will inspect in this notebook whether we can uncover the `buffalo`'s protected attribute using a machine learning model trained on the 49 points. If the model is privcy preserving, we should not be able to do this any better than if we did not have the model in hand. If not, then we will be significantly more confident by virtue of having access to the (outputs of the) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf16732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b58949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"privacy_data.pkl\", \"rb\"))\n",
    "\n",
    "X = data['X'].to_numpy()\n",
    "y = data['y'].to_numpy()\n",
    "attr = data['z'].to_numpy()   # The attributes of the database entries.\n",
    "x = data['animal'].to_numpy() # The targeted individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f57cefd",
   "metadata": {},
   "source": [
    "The analysis you are expected to critique begins below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb71abb",
   "metadata": {},
   "source": [
    "## <center>Differentially Private Logistic Regression for AwA2</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa842b4",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Standard preprocessing techniques are applied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aca43f",
   "metadata": {},
   "source": [
    "## Finding F\n",
    "\n",
    "Implemented a custom `test_train_split` function so that we can split the attributes as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9ee25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_split_custom(X, y, attrs, test_size=0.2):\n",
    "    \n",
    "    # Shuffle X and y exactly the same!\n",
    "    idx = np.random.permutation(X.shape[0])\n",
    "    train_idx = int((1 - test_size) * len(X))\n",
    "    \n",
    "    training_idx, test_idx = idx[:train_idx], idx[train_idx:]\n",
    "    \n",
    "    # Split your dataset \n",
    "    X_train = X[training_idx,:]\n",
    "    X_test = X[test_idx,:]\n",
    "    \n",
    "    y_train = y[training_idx]\n",
    "    y_test = y[test_idx]\n",
    "    \n",
    "    attrs_train = attrs[training_idx]\n",
    "    attrs_test = attrs[test_idx]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, attrs_train, attrs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb284a6c",
   "metadata": {},
   "source": [
    "## Finding E\n",
    "\n",
    "The data should be scaled on just the training data. This is so that we dont 'learn' anything from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16e8b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (39, 5)\n",
      "y train shape: (39,)\n",
      "X test shape: (10, 5)\n",
      "y test shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test, attrs_train, attrs_test = train_test_split(X, y, attr, test_size=0.2)\n",
    "# X_train, X_test, y_train, y_test, attrs_train, attrs_test = test_train_split_custom(X, y, attr, test_size=0.2)\n",
    "\n",
    "# scaler = StandardScaler().fit(X)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"X train shape:\", X_train.shape)\n",
    "print(\"y train shape:\", y_train.shape)\n",
    "print(\"X test shape:\", X_test.shape)\n",
    "print(\"y test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042f4c1c",
   "metadata": {},
   "source": [
    "## The Privacy Mechanism\n",
    "\n",
    "Below, we will implement the mechanism that returns responses from the machine learning model given queries from the data analyst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea4d801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class Mechanism:\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __init__(self, database, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def respond(query):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ecdefa",
   "metadata": {},
   "source": [
    "First, we cover the machine learning model. We will use unregularied logistic regression to map the feature vector $x \\in \\{0, 1\\}^5$ to its label $y \\in \\{0, 1\\}$. The `query` from the data analyst can come in four forms.\n",
    "- `all` - indicating that the mechanism should return responses (predicted labels) for all 49 training points in the database.\n",
    "- `flippers` - indicating that the mechanism should return responses (predicted labels) for all training points in the database that have flippers.\n",
    "- `no_flippers` - indicating that the mechanism should return responses (predicted labels) for all training points in the database that do not have flippers.\n",
    "- `x` - a single feature vector to be predicted by the model, passed as a `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67483311",
   "metadata": {},
   "source": [
    "We implement three mechanisms, each of which will produce the response in different ways while preserving privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6aba559",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mechanism1(Mechanism):\n",
    "    \n",
    "    def __init__(self, database, attr):\n",
    "        self.X, self.y = database\n",
    "        self.model = LogisticRegression().fit(self.X, self.y)\n",
    "        self.attr = attr\n",
    "        self.name = \"Mechanism 1\"\n",
    "        \n",
    "    def respond(self, query):\n",
    "        if isinstance(query, np.ndarray):\n",
    "            return self.model.predict(query.reshape(1, -1))[0]\n",
    "        elif query == \"all\":\n",
    "            return self.model.predict(self.X)\n",
    "        elif query == \"flippers\":\n",
    "            return self.model.predict(self.X[self.attr == 1])\n",
    "        elif query == \"no_flippers\":\n",
    "            return self.model.predict(self.X[self.attr == 0])\n",
    "        else:\n",
    "            raise ValueError(\"'query' must be 'all', 'flippers', 'no_flippers', or a numpy.ndarry object.\")\n",
    "\n",
    "class Mechanism2(Mechanism):\n",
    "    \n",
    "    def __init__(self, database, attr, prob=0.9):\n",
    "        self.X, self.y = database\n",
    "        self.model = LogisticRegression().fit(self.X, self.y)\n",
    "        self.attr = attr\n",
    "        self.name = \"Mechanism 2\"\n",
    "        self.prob = prob\n",
    "        \n",
    "    def respond(self, query):\n",
    "        if isinstance(query, np.ndarray):\n",
    "            coin = np.random.binomial(1, self.prob)\n",
    "            if coin == 1:\n",
    "                return self.model.predict(query.reshape(1, -1))[0]\n",
    "            else:\n",
    "                return np.random.binomial(1, 0.5)\n",
    "        elif query == \"all\":\n",
    "            X = self.X\n",
    "        elif query == \"flippers\":\n",
    "            X = self.X[self.attr == 1]\n",
    "        elif query == \"no_flippers\":\n",
    "            X = self.X[self.attr == 0]\n",
    "        else:\n",
    "            raise ValueError(\"'query' must be 'all', 'flippers', 'no_flippers', or a numpy.ndarry object.\")\n",
    "            \n",
    "        y = self.model.predict(X)\n",
    "        coins = np.random.binomial(1, self.prob, size=y.shape)\n",
    "        random_response = np.random.binomial(1, 0.5, size=y.shape)\n",
    "        \n",
    "        return y * coins + random_response * (1 - coins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f03ee",
   "metadata": {},
   "source": [
    "## Finding B:\n",
    "\n",
    "There is a small bug, where the 'scale' parameter is not used. We comment this out from the class constructor. \n",
    "\n",
    "Moreover, M3 is not differentially private. Once the noise added to the data is figured out, the adversary can find out all the information. This can be by sampling from the mechanism thousands of times. A better alternative would be to use the Laplace distribution to add the noise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e0704ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mechanism3(Mechanism):\n",
    "    \n",
    "    # def __init__(self, database, attr, scale=1):\n",
    "    def __init__(self, database, attr):\n",
    "        self.X, self.y = database\n",
    "        self.model = LogisticRegression().fit(self.X, self.y)\n",
    "        self.attr = attr\n",
    "        self.name = \"Mechanism 3\"\n",
    "        # self.scale = scale\n",
    "        \n",
    "    def respond(self, query):\n",
    "        if isinstance(query, np.ndarray):\n",
    "            noise = np.random.uniform(-0.1, 0.1, size=query.shape)\n",
    "            return  self.model.predict((query + noise).reshape(1, -1))[0]\n",
    "        elif query == \"all\":\n",
    "            X = self.X\n",
    "        elif query == \"flippers\":\n",
    "            X = self.X[self.attr == 1]\n",
    "        elif query == \"no_flippers\":\n",
    "            X = self.X[self.attr == 0]\n",
    "        else:\n",
    "            raise ValueError(\"'query' must be 'all', 'flippers', 'no_flippers', or a numpy.ndarry object.\")\n",
    "            \n",
    "        X = X + np.random.uniform(-0.1, 0.1, size=X.shape)\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09133323",
   "metadata": {},
   "source": [
    "## Finding C\n",
    "\n",
    "Here we implement the laplace mechanism to show how we can make mechanism 1 and 3 differentially private."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d968d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceMechanism(Mechanism):\n",
    "    \n",
    "    def __init__(self, database, attr, scale=0.8):\n",
    "        self.name = \"Laplace\"\n",
    "        self.X, self.y = database\n",
    "        self.model = LogisticRegression().fit(self.X, self.y)\n",
    "        self.attr = attr\n",
    "        self.scale = scale # Parameter for noise.\n",
    "        \n",
    "    def respond(self, query):\n",
    "        if isinstance(query, np.ndarray):\n",
    "            X = query + np.random.laplace(scale=self.scale, size=query.shape)\n",
    "            return self.model.predict(np.array([X]).reshape(1, -1))[0]\n",
    "        elif query == \"all\":\n",
    "            X = self.X\n",
    "        elif query == \"flippers\":\n",
    "            X = self.X[self.attr == 1]\n",
    "        elif query == \"no_flippers\":\n",
    "            X = self.X[self.attr == 0]\n",
    "        else:\n",
    "            raise ValueError(\"'query' must be 'all', 'flippers', 'no_flippers', or a numpy.ndarry object.\")\n",
    "        \n",
    "        X = X + np.random.laplace(scale=self.scale, size=X.shape)\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee41317",
   "metadata": {},
   "source": [
    "## Finding F\n",
    "\n",
    "We should only use the X_train and y_train to train the mechanisms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee0bd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database = (X, y)\n",
    "database = (X_train, y_train)\n",
    "\n",
    "m1 = Mechanism1(database, attrs_train)\n",
    "m2 = Mechanism2(database, attrs_train)\n",
    "m3 = Mechanism3(database, attrs_train)\n",
    "m4 = LaplaceMechanism(database, attrs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b1b540",
   "metadata": {},
   "source": [
    "## Finding A\n",
    "\n",
    "There is no randomness that is added into this mechanism. Each time we query m1 using 'no_flippers', we always receive a response that contains mostly 0's. This implies that all animals that do not have flippers, mostly do not live in the ocean. \n",
    "\n",
    "When we query the 'x' animal, we always get a prediction of 0; 'x' does not live in the ocean. \n",
    "\n",
    "As a result, we can predict, with a high certainty, that 'x' does not have flippers. Thus, this mechanism is not differentially private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c299287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flippers: 0.8333333333333334\n",
      "No Flippers: 0.0\n",
      "\"x\": 0\n"
     ]
    }
   ],
   "source": [
    "label_no_flippers = m1.respond('no_flippers').mean()\n",
    "label_flippers = m1.respond('flippers').mean()\n",
    "label = m1.respond(x)\n",
    "\n",
    "print(f'Flippers: {label_flippers}\\nNo Flippers: {label_no_flippers}\\n\"x\": {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befa0996",
   "metadata": {},
   "source": [
    "## The Advarsarial Attack\n",
    "\n",
    "We justify our claim of privacy by showing that an attack fails. In other words, we want the probabilities surrounding whether the targetted animal (`buffalo`) having the attribute `flipper` to not change very much given the response $\\hat{y}$from the mechanism. The prior probability (that is, prior to calling the mechanism) of having `flippers` is estimated using the number of animals in the training set that have flippers, which we assume is known by the attacker. We want:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left(\\text{flippers}\\mid \\hat{y}(\\text{buffalo}) =\\text{ocean}\\right) \\approx \\mathbb{P}\\left(\\text{flippers}\\right)\n",
    "$$\n",
    "\n",
    "If we are much more confident about the value of this protected attribute (i.e. the probabilities are significantly higher or lower) after using the prediction for the `ocean` attribute of `buffalo` from the model, then the mechanism has failed to protect privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad021371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior: 0.154\n",
      "Mechanism 1 Posterior: 0.182\n",
      "Mechanism 2 Posterior: 0.180\n",
      "Mechanism 3 Posterior: 0.182\n",
      "Laplace Posterior: 0.179\n"
     ]
    }
   ],
   "source": [
    "# Use Bayes rule to get a value for the probability of `x` having attr == flippers.\n",
    "np.random.seed(123)\n",
    "\n",
    "prior = attrs_train.mean()\n",
    "print(\"Prior: %0.3f\" % prior)\n",
    "\n",
    "for mech in [m1, m2, m3, m4]:\n",
    "    label = mech.respond(x)\n",
    "\n",
    "    prob_1_given_attr_1 = mech.respond(\"flippers\").mean()\n",
    "    prob_1_given_attr_0 = mech.respond(\"no_flippers\").mean()\n",
    "\n",
    "    if label == 1:\n",
    "        prob_label_given_attr_1 = prob_1_given_attr_1\n",
    "        prob_label_given_attr_0 = prob_1_given_attr_0\n",
    "    else:\n",
    "        prob_label_given_attr_1 = prob_1_given_attr_0\n",
    "        prob_label_given_attr_0 = prob_1_given_attr_1\n",
    "        \n",
    "    posterior = prior * prob_label_given_attr_0 / (prior * prob_label_given_attr_1 + (1 - prior) *  prob_label_given_attr_0)\n",
    "\n",
    "    print(\"%s Posterior: %0.3f\" % (mech.name, posterior))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfa5f4",
   "metadata": {},
   "source": [
    "Clearly, these probabilities have not changed very much from the prior. Thus, we can be assured that each mechanism preserves privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b3956b",
   "metadata": {},
   "source": [
    "## Finding G\n",
    "\n",
    "Bayes rule has been incorrectly implemented in the cell block above. This incorrect implementation leads to the prior and posterior probabilities having a similar value. However, this is not the case. The correct implementation, below, shows that the prior and posterior probabilities are very different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c13b4d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior: 0.154\n",
      "Mechanism 1 Posterior: 0.029\n",
      "Mechanism 2 Posterior: 0.059\n",
      "Mechanism 3 Posterior: 0.029\n",
      "Laplace Posterior: 0.061\n"
     ]
    }
   ],
   "source": [
    "# Use Bayes rule to get a value for the probability of `x` having attr == flippers.\n",
    "np.random.seed(123)\n",
    "\n",
    "prior = attrs_train.mean()\n",
    "# prior = attr.mean()\n",
    "print(\"Prior: %0.3f\" % prior)\n",
    "\n",
    "for mech in [m1, m2, m3, m4]:\n",
    "    label = mech.respond(x)\n",
    "\n",
    "    prob_1_given_attr_1 = mech.respond(\"flippers\").mean()\n",
    "    prob_1_given_attr_0 = mech.respond(\"no_flippers\").mean()\n",
    "\n",
    "    if label == 1:\n",
    "        prob_label_given_attr_1 = prob_1_given_attr_1    #P(ocean|flippers)\n",
    "        prob_label_given_attr_0 = prob_1_given_attr_0    #P(ocean|no flippers)\n",
    "    else:\n",
    "        prob_label_given_attr_1 = 1 - prob_1_given_attr_1   #P(not ocean|flippers)\n",
    "        prob_label_given_attr_0 = 1 - prob_1_given_attr_0   #P(not ocean|no flippers)\n",
    "        \n",
    "    posterior = prior * prob_label_given_attr_1 / (prior * prob_label_given_attr_1 + (1 - prior) *  prob_label_given_attr_0)\n",
    "\n",
    "    print(\"%s Posterior: %0.3f\" % (mech.name, posterior))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab45fd77",
   "metadata": {},
   "source": [
    "## Maintaining Accuracy\n",
    "\n",
    "Trivially, we can always preserve privacy by injecting a sufficiently large amount of noise. While this may be good by one metric, we might completely destroy the predictive performance of the model! It is important to maintain a balance such that we still perform well on a test set, which we inspect below. Note that this step would normally be done on a validation set, and final performance would be computed on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffc77b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mechanism 1 Test Accuracy: 1.00\n",
      "Mechanism 2 Test Accuracy: 0.90\n",
      "Mechanism 3 Test Accuracy: 1.00\n",
      "Laplace Test Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "for mech in [m1, m2, m3, m4]:\n",
    "    y_pred = np.array([mech.respond(x) for x in X_test])\n",
    "    print(\"%s Test Accuracy: %0.2f\" % (mech.name, accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790cf776",
   "metadata": {},
   "source": [
    "## Finding D - Checking for Differential Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ff0d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_response_region(y):\n",
    "    return y == 1\n",
    "\n",
    "def check_differentially_private(epsilon, mechanism1, mechanism2, query, is_in_response_region, num_sims=1000):\n",
    "    \n",
    "    y1 = []\n",
    "    y2 = []\n",
    "    for i in range(num_sims):\n",
    "        # Collect responses of each mechanism into 'y1' and 'y2'.\n",
    "        y1.append(mechanism1.respond(query))\n",
    "        y2.append(mechanism2.respond(query))\n",
    "       \n",
    "    # Compute probability that the responses are in the response region.\n",
    "    prob1 = is_in_response_region(np.array(y1)).sum() / num_sims\n",
    "    prob2 = is_in_response_region(np.array(y2)).sum() / num_sims\n",
    "    \n",
    "    # Check definition, and set to Boolean below.\n",
    "    is_differentially_private = (prob1 <= np.exp(epsilon) * prob2)   \n",
    "    \n",
    "    return is_differentially_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8772eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, y2 = X_train.copy(), y_train.copy()\n",
    "X2[4, 3] = 1 - X[4, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7c82ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = (X2, y2)\n",
    "\n",
    "m12 = Mechanism1(database, attrs_train)\n",
    "m22 = Mechanism2(database, attrs_train)\n",
    "m32 = Mechanism3(database, attrs_train)\n",
    "m42 = LaplaceMechanism(database, attrs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0383298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mechanism 1, Mechanism 1: Is Private?: True\n",
      "Mechanism 2, Mechanism 2: Is Private?: True\n",
      "Mechanism 3, Mechanism 3: Is Private?: True\n",
      "Laplace, Laplace: Is Private?: True\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.001\n",
    "\n",
    "for mech in [(m1, m12), (m2, m22), (m3, m32), (m4, m42)]:\n",
    "    mech1, mech2 = mech\n",
    "    is_diff_private = check_differentially_private(epsilon, mech1, mech2, x, is_in_response_region)\n",
    "    \n",
    "    print(f'{mech1.name}, {mech2.name}: Is Private?: {is_diff_private}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
